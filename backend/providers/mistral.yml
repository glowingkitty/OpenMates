# backend/providers/mistral.yml
#
# Configuration for Mistral AI services.

provider_id: "mistral"
name: "Mistral AI"
description: "AI models and services from Mistral AI."
logo_svg: "logos/mistral.svg" # Path for UI, relative to logos directory

models:
  - id: "mistral-small-latest" # Official model ID
    name: "Mistral Small"
    description: >-
      Mistral AI's fast and cost-effective model, optimized for low latency.
    country_origin: "FR" # ISO 3166-1 alpha-2 country code for model origin (France)
    for_app_skill: "ai.ask" # This model is for the AI ask skill (text generation)
    allow_auto_select: true
    external_ids: # Mapping to external leaderboard IDs for cross-referencing
      lmarena: "mistral-small-latest"
      openrouter: "mistralai/mistral-small-3.2-24b-instruct"
    input_types:
      - text
      - image
    output_types:
      - text
    default_server: "mistral" # Default to direct Mistral API
    servers:
      - id: "mistral"
        name: "Mistral"
        model_id: "mistral-small-latest" # Direct Mistral API model ID
      - id: "google"
        name: "Google Cloud Vertex AI"
        # Google Vertex AI model identifier for Mistral Small 3.1 (25.03)
        model_id: "mistral-small-2503"
      - id: "openrouter"
        name: "OpenRouter"
        # OpenRouter model identifier
        model_id: "mistralai/mistral-small-3.2-24b-instruct"
    # Full reference for API calls would be "mistral/mistral-small-latest"
    # (or similar based on client)
    pricing: # Model-specific base pricing (example structure)
      tokens:
        input:
          per_credit_unit: 3300 # 1 credit per 3,300 input tokens
        output:
          per_credit_unit: 1100 # 1 credit per 1,100 output tokens
    costs:
      input_per_million_token:
        price: 0.10
        currency: USD
        max_context: 128000 # Max context window.
      output_per_million_token:
        price: 0.30
        currency: USD
        max_context: 128000

  - id: "mistral-medium-latest" # Official model ID
    name: "Mistral Medium"
    description: >-
      State-of-the-art performance. Simplified enterprise deployments.
      Cost-efficient.
    country_origin: "FR" # ISO 3166-1 alpha-2 country code for model origin (France)
    for_app_skill: "ai.ask" # This model is for the AI ask skill (text generation)
    allow_auto_select: true
    external_ids: # Mapping to external leaderboard IDs for cross-referencing
      lmarena: "mistral-medium-3.1"
      openrouter: "mistralai/mistral-medium-3.1"
    input_types:
      - text
      - image
    output_types:
      - text
    default_server: "mistral" # Default to direct Mistral API
    servers:
      - id: "mistral"
        name: "Mistral"
        model_id: "mistral-medium-latest" # Direct Mistral API model ID
      - id: "openrouter"
        name: "OpenRouter"
        model_id: "mistralai/mistral-medium-3.1" # OpenRouter model identifier
    pricing:
      tokens:
        input:
          per_credit_unit: 850 # 1 credit per 850 input tokens
        output:
          per_credit_unit: 170 # 1 credit per 170 output tokens
    costs:
      input_per_million_token:
        price: 0.40
        currency: USD
        max_context: 128000
      output_per_million_token:
        price: 2.00
        currency: USD
        max_context: 128000

  - id: "devstral-2512" # Official model ID
    name: "Devstral 2"
    description: >-
      Our frontier code agents model for solving software engineering tasks;
      excels at using tools to explore codebases, editing multiple files and
      power software engineering agents.
    country_origin: "FR" # ISO 3166-1 alpha-2 country code for model origin (France)
    for_app_skill: "ai.ask" # This model is for the AI ask skill (text generation)
    allow_auto_select: true
    external_ids: # Mapping to external leaderboard IDs for cross-referencing
      lmarena: "devstral-2512"
      openrouter: "mistralai/devstral-2512"
    input_types:
      - text
    output_types:
      - text
    default_server: "mistral" # Default to direct Mistral API
    servers:
      - id: "mistral"
        name: "Mistral"
        model_id: "devstral-2512" # Direct Mistral API model ID
      - id: "openrouter"
        name: "OpenRouter"
        # OpenRouter model identifier
        model_id: "mistralai/devstral-2512"
    pricing:
      tokens:
        input:
          # 1 credit per 850 input tokens (calculated from $0.4/M tokens)
          per_credit_unit: 850
        output:
          # 1 credit per 170 output tokens (calculated from $2/M tokens)
          per_credit_unit: 170
    costs:
      input_per_million_token:
        price: 0.40
        currency: USD
        max_context: 256000 # Max context window: 256k tokens
      output_per_million_token:
        price: 2.00
        currency: USD
        max_context: 256000
    features:
      max_output_tokens: 128000
      tool_use: true
      streaming: true
      agents: true

# Pricing Formula:
# 1. Cost per token = (your_cost_usd_per_million * markup) / 1,000,000
# 2. Tokens per credit = credit_value_usd / cost_per_token
#
# Where:
# - credit_value_usd = 0.001 (110 USD / 110,000 credits)
# - markup = 3 (3x your cost)
#
# Simplified: tokens_per_credit = 0.001 /
# ((your_cost_per_million * 3) / 1,000,000)
# Or even simpler: tokens_per_credit = 333.33 / your_cost_per_million
#
# Examples:
# - Input ($1.25/M): 333.33 / 1.25 = 267 tokens/credit → round to 300
# - Output ($10/M): 333.33 / 10 = 33 tokens/credit → round to 30

# FOR PER-UNIT PRICING (images, API calls, etc.):
# 1. Your price to user = your_cost_per_unit * markup
# 2. Credits per unit = your_price_to_user / credit_value_usd
#
# Simplified: credits_per_unit = (your_cost_per_unit * 3) / 0.001
# Or even simpler: credits_per_unit = your_cost_per_unit * 3000
#
# Per-Unit Examples:
# - Image ($0.04 each): 0.04 * 3000 = 120 credits per image
# - API call ($0.01 each): 0.01 * 3000 = 30 credits per call
