# backend/providers/alibaba.yml
# Alibaba provider config (Qwen models).
# Qwen models can be accessed via OpenRouter (with Cerebras backend) or directly via Cerebras API.

provider_id: "alibaba"
name: "Alibaba"
description: "Alibaba Cloud AI - Qwen models"
logo_svg: "logos/alibaba.svg"

models:
  - id: "qwen3-235b-a22b-2507"
    name: "Qwen3 235B A22B (2507)"
    description: "Qwen3 235B A22B with ultra-fast inference. Can be served via OpenRouter (with Cerebras backend) or directly via Cerebras API. Strong general and reasoning performance."
    input_types:
      - text
      - image
    output_types:
      - text
    default_server: "cerebras"  # Default to Cerebras for ultra-fast inference
    servers:
      - id: "openrouter"
        name: "OpenRouter"
        model_id: "qwen/qwen3-235b-a22b-2507"  # OpenRouter's model identifier
      - id: "cerebras"
        name: "Cerebras"
        model_id: "qwen-3-235b-a22b-instruct-2507"  # Direct Cerebras model identifier (Preview model)
    # Provider overrides for OpenRouter routing (force Cerebras backend)
    provider_overrides:
      order: ["cerebras"]
      allow_fallbacks: true
    pricing:
      tokens:
        input:
          per_credit_unit: 700
        output:
          per_credit_unit: 250
    costs:
      input_per_million_token:
        price: 0.60
        currency: USD
        max_context: 131000
      output_per_million_token:
        price: 1.20
        currency: USD
        max_context: 131000
