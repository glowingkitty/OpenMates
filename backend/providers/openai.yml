# backend/providers/openai.yml
#
# Configuration for OpenAI models via OpenRouter gateway.

provider_id: "openai"
name: "OpenAI"
description: "AI models and services from OpenAI."
logo_svg: "logos/openai.svg" # Path for UI, relative to a common logos directory

models:
  - id: "gpt-5" # Model ID without provider prefix
    name: "GPT-5"
    description: "The best model for coding and agentic tasks across domains"
    input_types:
      - text
      - image
    output_types:
      - text
    # Using GPT-5 via openai api
    pricing: # Model-specific base pricing
      tokens: 
        input:
          per_credit_unit: 300 # 1 credit per 300 input tokens
        output:
          per_credit_unit: 30 # 1 credit per 30 output tokens
    costs:
      input_per_million_token:
        price: 1.25
        currency: USD
        max_context: 400000 # Max context window for GPT-5
      output_per_million_token:
        price: 10.00
        currency: USD
        max_context: 400000
    features:
      max_output_tokens: 128000
      knowledge_cutoff: "2024-10-01"
      reasoning_token_support: true
  
        
  - id: "gpt-oss-120b" # Model ID without provider prefix
    name: "GPT-OSS-120b"
    description: "Open-source large language model with 120B parameters, served via Cerebras through OpenRouter."
    input_types:
      - text
    output_types:
      - text
    default_server: "openrouter" # Default server for this model
    servers:
      - id: "openrouter"
        name: "OpenRouter API"
    # Provider overrides to force Cerebras as the provider
    provider_overrides:
      order: ["cerebras"]   # try Cerebras first (and only)
      allow_fallbacks: true # fail fast if Cerebras is down
    # Full reference for API calls would be "openrouter/openai/gpt-oss-120b"
    pricing: # Model-specific base pricing
      tokens:
        input:
          per_credit_unit: 1500 # 1 credit per 1500 input tokens (0.25 USD per 1M tokens)
        output:
          per_credit_unit: 500  # 1 credit per 500 output tokens (0.69 USD per 1M tokens)
    costs:
      input_per_million_token:
        price: 0.25
        currency: USD
        max_context: 131000 # Max context window for GPT-OSS-120b
      output_per_million_token:
        price: 0.69
        currency: USD
        max_context: 131000
    characteristics:
      - "reasoning model, with the tendency to create long responses"
      - "fast responses"
      - "has a very strong tendency to always include tables in the response"

# Pricing Formula:
# 1. Cost per token = (your_cost_usd_per_million * markup) / 1,000,000
# 2. Tokens per credit = credit_value_usd / cost_per_token
# 
# Where:
# - credit_value_usd = 0.001 (110 USD / 110,000 credits)
# - markup = 3 (3x your cost)
#
# Simplified: tokens_per_credit = 0.001 / ((your_cost_per_million * 3) / 1,000,000)
# Or even simpler: tokens_per_credit = 333.33 / your_cost_per_million
#
# Examples:
# - Input ($1.25/M): 333.33 / 1.25 = 267 tokens/credit → round to 300
# - Output ($10/M): 333.33 / 10 = 33 tokens/credit → round to 30

# FOR PER-UNIT PRICING (images, API calls, etc.):
# 1. Your price to user = your_cost_per_unit * markup
# 2. Credits per unit = your_price_to_user / credit_value_usd
#
# Simplified: credits_per_unit = (your_cost_per_unit * 3) / 0.001
# Or even simpler: credits_per_unit = your_cost_per_unit * 3000
#
# Per-Unit Examples:
# - Image ($0.04 each): 0.04 * 3000 = 120 credits per image
# - API call ($0.01 each): 0.01 * 3000 = 30 credits per call
