name: |
  Code
description: |
  Write, test, improve and execute code.
icon_image: |
  coding.svg
icon_colorgradient:
  start: |
    #155D91
  end: |
    #42ABF4

settings_and_memories:
  - id: |
      preferred_languages_frameworks_tech
  - id: |
      current_projects
  - id: |
      past_projects
  - id: |
      want_to_learn
# IMPORTANT lerning:
# if we let ai code for too long extensive code changes and then start to test it, it becomes a huge broken mess. instead we need to find other ways. Maybe by reminding llm to break tasks down into smaller steps (that also allows for placebolder code), and build it up so that we can test individual steps better if they work and if so we continue to the next step.

#**Development approach:**
#- Break large tasks into smaller, testable increments instead of letting AI implement extensive changes all at once
#- Use placeholder-driven architecture - stub out structure first, then fill in components one by one
#- Validate each step before moving to the next (compile, test, verify functionality)
#- Treat AI as pair programming partner requiring frequent check-ins rather than autonomous contractor

#**Chat specific files**
#- todo.md -> to manage all 

#**Project awareness files:**
#- Keep existing `todo.md`, `architecture.md`, and project structure
#- Add automated file generation that extracts real project state (dependencies, linter warnings, test coverage)
#- Use `changelog_since_commit.md` for current session changes, reset on each git commit
#- Maintain `recent_commits.md` showing last N commits for historical context

#**Context management:**
#- Start each session by having AI review and summarize key project files
#- Explicitly reference documentation files when requesting changes
#- Use git hooks or scripts to automatically sync documentation with commits
#- Focus on objective, automatically-generated project state rather than manually maintained status files

#**Testing integration:**
#- Write tests before or alongside implementation
#- Have AI explain how each component would be tested
#- Catch issues early when they're easier to trace and fix​​​​​​​​​​​​​​​​

#- also keep in mind when building a vscode extension that vscode extensions can also access terminal window names and write to them but not see the content of existing terminal windows.

# Step 1 - Planning: User writes down a plan of requirements of what they want and what they think how things should work
# Step 2 - Refinement: User tells ai the plan, ai checks for files in the existing project to better understand the project in the context of the requirements and then has a conversation to clarify the requirements / update them and creates a todo list or in case of larger projects / changes multiple files with todos which should result in testabable units / changes to the project. Ideally this is split up in a way that multiple ais can work on the tasks without creating colliding code changes.
# Step 3 - Coding & Feedback loop: the ai starts to update the code / implement the changes for the tasks block. Ideally multiple ais can work on the various tasks blocks without colliding with each other. Ideally the ais dont need further feedback because they have asked all relevant details in the planning & refinement stages. But when conflicts / unclear situations do occur, they ask the user for input and then continue the work based on the input.
# Step 4 - Testing: the ai is generating tests or test instructions and either runs them by itself or asks the user to
# Step 5 - Documentation: once the ai has completed the tasks or block of tasks, it updates the todo markdown file, updates the changelog file and creates or updates documentation files.
# Interruption: if the chat is getting too long, the ai is updating the todo's and changelog and starts a fresh chat

# skills:
# add issue as markdown file, for llm to better process
# with structure:
# ## Summary
# Brief description of the issue

# ## Steps to Reproduce
# 1. First step
# 2. Second step
# 3. Third step

# ## Expected Behavior
# What should happen

# ## Actual Behavior
# What actually happens

# ## Environment
# - OS: 
# - Browser/Version:
# - Project Version:

# ## Additional Context
# Screenshots, logs, or other relevant information


skills:
  - id: |
      clean_repo
    name: |
      Clean repo
    description: |
      Check the local repo and its code for unused imports, functions, variables - and auto remove them.

  - id: |
      get_issues
    name: |
      Get issues
    description: |
      Get issues from GitHub or GitLab for a project. Either all or with specific tags.

  - id: |
      add_issue
    name: |
      Add issue
    description: |
      Add an issue to your GitHub or GitLab project.

  - id: |
      remove_secrets
    name: |
      Remove secrets
    description: | # use gitleaks, git log -p --all -S "max mustermann" -i, git filter (to remove)
      Check the repo and its code for api keys, passwords, tokens, name, addresses, phone numbers, emails and other sensitive information - and auto remove them.

  - id: |
      get_project_overview
    name: |
      Get project overview
    description: |
      Create an AST overview of all folders, files and functions inside the files, to get a good understanding of the local project architecture.

focuses:
# During development, use the following focuses:
# TODO: implement in Sophia system prompt instruction to use these focuses
# Step 1: Plan changes (load project overview (if project exists), ask questions and create files:
# - `.context/{subject}_todo.md` (include unit tests of sub task changes/ instructions what to test manually)
# - `.context/{subject}_requirements.md`
# - `.context/{subject}_architecture.md`
  - id: |
      plan_project
    name: |
      Plan project
    description: |
      Plan a project or changes to a project. Create collaboratively the requirements.md, architecture.md and todo.md files for the changes or project.
    stage: |
      planning
    process:
      - ""

# Step 2: Write & test & debug code (get content of these files and then start or continue implementing them, step by step with placeholde architecture for complex changes. Auto write & run unit tests and for tests that user needs to executed, ask user / give test instructions. If an error occurs: ask for what is going wrong, ask for logs, then fix it. If major architectural decisions have to be made which aren't defined in /docs/architecture/README.md, then ask user instead of implementing changes with huge consequences for the project & update plan files. When changes have been applied, add to`.tempcontext/{subject}_changelog.md`. Instruct the LLM also to create unittest and run them or when that isn't practical (for web apps for sample) output test instructions to `.tempcontext/{subject}_testing.md`. Once new solution is implemented, also create or update documentation in README files of folders where files have been updated / added.
# Important:
# - keep /docs folder updated with .md files for humans and LLMs about general processing
# - keep folder specific readme files updated with overview of folders / files and their purpose / basic functionamity (include automated generated folder overview structure with functions / classes & another file with "issues.md" with linter errors which eventually should be handled in GitHub issues.)
# /.tempcontext (on gitignore) for file for temporary context only

# include license / SPFX for REUSE project automatically for each file?

  - id: |
      write_test_debug_document
    name: |
      Write, test, debug & document
    description: |
      Write, test and debug code changes. When task is complete, update documentation. For more complex changes: after previous planning phase.
    stage: |
      planning
    process:
      - "ask users clearifying question to make the requirements clear and create requirements.md file"
      - "for more complex tasks: create todo.md file and keep it updated with progress. Include filepaths or function names / variable names relevant."
      - "if problem can't be solved within a few steps, ask if new approach should be tried or if requirements should be redefined"
    # systemprompt just an early placeholder. Nowhere near complete.
    systemprompt: |
      You are a programming expert.

  - id: |
      analyze_logs
    name: |
      Analyze logs
    description: |
      Helps you to understand and analyze logs to see what is going on, what is broken, what should be improved, etc
    stage: |
      planning
    process:
      - ""

  - id: |
      improve_issue
    name: |
      Improve issue
    description: |
      Helps you to improve an issue, bug or feature request, by adding clearifing details, remove unnecessary details and logs and more.
    stage: |
      planning
    process:
      - ""

  - id: |
      learn_new_tech
    name: |
      Learn new tech
    description: |
      Start learning a new programming language, framework or other new technology.
    process:
      - "asks user what their learning goal is (understanding a specific part of a new technology, extending knowledge, etc.)
      - "show examples, suggest a sample project, consider Q&As or other learning methods for understanding a tech"
      - "goal is to assist software developers who don't want to use AI assisted coding but still profit from the use of AI (and ease the developers into accepting AI support more)."

  - id: |
      explain_project
    name: |
      Explain project
    description: |
      Clones a git repo, analyzes it and explains its architecture, issues and more.
    stage: |
      planning

  - id: |
      research_solutions
    name: |
      Research solitions
    description: |
      Brainstorm & research what tech would work well for the requirements of the user.
    stage: |
      planning

  - id: |
      code_walkthrough
    name: |
      Code walkthrough
    description: |
      Talk through code problems step-by-step. Think through issues without jumping straight to solutions."
    stage: |
      planning

  - id: |
      setup_infrastructure
    name: |
      Setup infrastructure
    description: |
      Get assistance for setting up a software or infrastructure.
    stage: |
      planning
    process:
      - "mate asks multiple questions to understand what user wants to setup and in what context"
      - "mate asks clearification questions if first response is not clear"
      - "mate provides step-by-step instructions for setting up the software or infrastructure the user asked for"
      - "mate explains the first step, then waits for user feedback, then continues with the next step if step is successful, etc."
      - "at the end of the successful setup process, mate suggests saving the setup instructions as markdown (for humans), terraform, ansible playbook or cloud-init script (depending on the context)"
    # systemprompt just an early placeholder. Nowhere near complete.
    systemprompt: |
      You are an expert in setting up infrastructure and software via terminal.