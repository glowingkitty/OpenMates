{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0429d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (1.99.3)\n",
      "Requirement already satisfied: python-dotenv in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: azure-identity in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (1.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-identity) (1.35.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-identity) (45.0.6)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-identity) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: certifi in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: pycparser in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/superdev/projects/OpenMates/tree-sitter-env/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai python-dotenv azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3196a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading environment from /home/superdev/projects/OpenMates/.env\n"
     ]
    }
   ],
   "source": [
    "import os, time, json, pathlib, sys, logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------- Configure logger (avoid duplicate handlers in notebooks) ----------\n",
    "logger = logging.getLogger(\"azure_openai_demo\")\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setFormatter(logging.Formatter(\"[%(levelname)s] %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# ---------- Load .env (search upwards) ----------\n",
    "cwd = pathlib.Path.cwd()\n",
    "env_path = None\n",
    "for parent in [cwd] + list(cwd.parents):\n",
    "    candidate = parent / \".env\"\n",
    "    if candidate.is_file():\n",
    "        env_path = candidate\n",
    "        break\n",
    "\n",
    "if env_path is None:\n",
    "    logger.warning(\"No .env file found â€“ you must set env vars manually.\")\n",
    "else:\n",
    "    logger.info(\"Loading environment from %s\", env_path)\n",
    "    load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4d97a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting streamed chat.completions response (model=gpt-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris.\n",
      "[INFO] Stream finished. Characters received: 6\n"
     ]
    }
   ],
   "source": [
    "# --- Streamed Azure OpenAI chat completion ---\n",
    "# This cell switches from a single, blocking response to streaming token-by-token output.\n",
    "# - We write tokens to stdout for smooth, real-time display in notebooks.\n",
    "# - We also use the configured logger (INFO level) for lifecycle messages and summaries.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import base64  # kept in case you uncomment the image example later\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# --- Configuration (env with sensible defaults for local testing) ---\n",
    "endpoint = os.getenv(\n",
    "    \"SECRET__OPENAI__AZURE__ENDPOINT_URL\",\n",
    "    \"https://micro-me2ldtrn-eastus2.cognitiveservices.azure.com/\",\n",
    ")\n",
    "deployment = os.getenv(\"SECRET__OPENAI__AZURE__DEPLOYMENT_NAME\", \"gpt-5\")\n",
    "subscription_key = os.getenv(\n",
    "    \"SECRET__OPENAI__AZURE__API_KEY\", \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    ")\n",
    "\n",
    "# --- Ensure a logger exists in this cell (in case cells run out-of-order) ---\n",
    "try:\n",
    "    logger  # type: ignore  # noqa: F821\n",
    "except NameError:\n",
    "    import logging\n",
    "\n",
    "    logger = logging.getLogger(\"azure_openai_demo\")\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        handler.setFormatter(logging.Formatter(\"[%(levelname)s] %(message)s\"))\n",
    "        logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Initialize Azure OpenAI client (key-based auth) ---\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "# IMAGE_PATH = \"YOUR_IMAGE_PATH\"\n",
    "# encoded_image = base64.b64encode(open(IMAGE_PATH, \"rb\").read()).decode(\"ascii\")\n",
    "\n",
    "# --- Prepare the chat prompt ---\n",
    "chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"What is the capital of France?\"\n",
    "                    # \"how do I integrate Oxylabs proxy into my python code? \"\n",
    "                    # \"and can I integrate it also with the youtube_transcript_api pip package?\"\n",
    "                ),\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Include speech result if speech is enabled\n",
    "messages = chat_prompt\n",
    "\n",
    "# --- Stream the completion token-by-token ---\n",
    "logger.info(\"Starting streamed chat.completions response (model=%s)\", deployment)\n",
    "\n",
    "accumulated_text_parts = []\n",
    "try:\n",
    "    stream = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages,\n",
    "        max_completion_tokens=16384,\n",
    "        stop=None,\n",
    "        stream=True,\n",
    "        timeout=120.0,\n",
    "    )\n",
    "\n",
    "    # Write tokens directly to stdout for real-time display in the notebook.\n",
    "    # We avoid 'print' and instead write raw tokens to stdout, while using the\n",
    "    # logger for high-level lifecycle messages and the final summary below.\n",
    "    for chunk in stream:\n",
    "        # Defensive checks because some SDK versions may emit non-delta or empty chunks\n",
    "        if not chunk or not getattr(chunk, \"choices\", None):\n",
    "            continue\n",
    "\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta is None:\n",
    "            continue\n",
    "\n",
    "        content_piece = getattr(delta, \"content\", None)\n",
    "        if content_piece:\n",
    "            sys.stdout.write(content_piece)\n",
    "            sys.stdout.flush()\n",
    "            accumulated_text_parts.append(content_piece)\n",
    "except Exception as exc:\n",
    "    logger.exception(\"Error while streaming response: %s\", exc)\n",
    "finally:\n",
    "    # Ensure a newline after streaming so the next cell's output starts cleanly\n",
    "    sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    final_text = \"\".join(accumulated_text_parts)\n",
    "    logger.info(\"Stream finished. Characters received: %d\", len(final_text))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-sitter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
